# Backend AI - YOLO Detection API

Backend FastAPI con WebSocket para detecciÃ³n de objetos en tiempo real usando YOLOv8.

## ğŸš€ InstalaciÃ³n

### 1. Crear entorno virtual (recomendado)

```bash
cd backend_ai
python -m venv venv

# Activar en Linux/Mac:
source venv/bin/activate

# Activar en Windows:
venv\Scripts\activate
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

**Nota:** Si tienes GPU NVIDIA, instala PyTorch con CUDA:
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### 3. Descargar modelo YOLO (automÃ¡tico al ejecutar)

El modelo `yolov8n.pt` se descargarÃ¡ automÃ¡ticamente la primera vez que ejecutes el servidor.

## ğŸƒ Ejecutar Servidor

```bash
python server.py
```

El servidor estarÃ¡ disponible en:
- **WebSocket:** `ws://localhost:8000/ws/detect`
- **HTTP API:** `http://localhost:8000/api/detect`
- **Health Check:** `http://localhost:8000/health`
- **Docs (Swagger):** `http://localhost:8000/docs`

## ğŸ“¡ Uso del WebSocket

### Desde el Frontend (React/TypeScript)

```typescript
// Conectar al WebSocket
const ws = new WebSocket('ws://localhost:8000/ws/detect');

// Enviar frame
const canvas = document.querySelector('canvas');
const imageBase64 = canvas.toDataURL('image/jpeg', 0.8);

ws.send(JSON.stringify({
  image: imageBase64
}));

// Recibir detecciones
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Detecciones:', data.detections);
  console.log('Advertencias:', data.warnings);
};
```

## ğŸ“¦ Respuesta del Servidor

```json
{
  "success": true,
  "detections": [
    {
      "bbox": [100, 200, 300, 400],
      "confidence": 0.85,
      "class": "bottle",
      "class_id": 39
    }
  ],
  "counts": {
    "bottle": 1,
    "person": 2
  },
  "warnings": [
    {
      "type": "bottle_detected",
      "message": "âš ï¸ Botella detectada - Debe ser retirada",
      "severity": "high"
    }
  ],
  "total_objects": 3,
  "timestamp": "2025-10-26T10:30:45.123456"
}
```

## ğŸ”§ ConfiguraciÃ³n

Copia `.env.example` a `.env` y modifica segÃºn necesites:

```bash
cp .env.example .env
```

Variables disponibles:
- `YOLO_MODEL`: Modelo a usar (yolov8n.pt, yolov8s.pt, yolov8m.pt)
- `YOLO_DEVICE`: cpu, cuda, o mps (Mac)
- `YOLO_CONF_THRESHOLD`: Umbral de confianza (0.0 - 1.0)

## ğŸ¯ Endpoints

### WebSocket: `/ws/detect`
- **PropÃ³sito:** DetecciÃ³n en tiempo real
- **Input:** JSON con campo `image` (Base64)
- **Output:** Detecciones en JSON

### POST: `/api/detect`
- **PropÃ³sito:** DetecciÃ³n Ãºnica (alternativa HTTP)
- **Body:** `{"image": "data:image/jpeg;base64,..."}`
- **Response:** JSON con detecciones

### GET: `/health`
- **PropÃ³sito:** Health check
- **Response:** Estado del servidor y modelo

### GET: `/model/info`
- **PropÃ³sito:** InformaciÃ³n del modelo cargado
- **Response:** Clases, umbral, device, etc.

## ğŸ“Š Performance Tips

1. **Usar modelo ligero:** `yolov8n.pt` es el mÃ¡s rÃ¡pido
2. **Reducir resoluciÃ³n:** Procesa frames a 640x480
3. **Ajustar FPS:** No enviar mÃ¡s de 10-15 frames/segundo
4. **GPU:** Si tienes NVIDIA GPU, cambia `device="cuda"`

## ğŸ› Troubleshooting

### Error: "Could not load model"
```bash
# Descargar modelo manualmente
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt
```

### Error: "No module named cv2"
```bash
pip install opencv-python
```

### Error de memoria
- Usa modelo mÃ¡s pequeÃ±o (yolov8n.pt)
- Reduce imgsz en yolo_detector.py (640 â†’ 320)
- Procesa menos frames por segundo

## ğŸ“ Estructura

```
backend_ai/
â”œâ”€â”€ server.py              # Servidor FastAPI principal
â”œâ”€â”€ yolo_detector.py       # Wrapper del modelo YOLO
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ .env.example          # Variables de entorno
â””â”€â”€ README.md             # Esta documentaciÃ³n
```

## ğŸ”— IntegraciÃ³n con Frontend

Ver documentaciÃ³n en `src/hooks/useYOLODetection.ts` (prÃ³ximo paso)
